{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1ffe4951-df80-4679-af4f-26d90f83f74d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"OnlineBankingAnalysis\").getOrCreate()\n",
    "loan_df = spark.read.csv(\"/FileStore/tables/loan.csv\", header=True, inferSchema=True)\n",
    "credit_df = spark.read.csv(\"/FileStore/tables/credit_card.csv\", header=True, inferSchema=True)\n",
    "txn_df = spark.read.csv(\"/FileStore/tables/txn.csv\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "46fad6e3-e956-43f7-acb5-9bbbbe4dd0fc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Perform cleaning operations\n",
    "loan_df = loan_df.dropna().dropDuplicates()\n",
    "credit_df = credit_df.dropna().dropDuplicates()\n",
    "txn_df = txn_df.dropna().dropDuplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "48a68928-5db0-49a6-a00c-689a06aabd0e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-----+\n|     Loan Category|count|\n+------------------+-----+\n|           HOUSING|   61|\n|        TRAVELLING|   48|\n|       BOOK STORES|    7|\n|       AGRICULTURE|   12|\n|         GOLD LOAN|   72|\n|  EDUCATIONAL LOAN|   17|\n|        AUTOMOBILE|   53|\n|          BUSINESS|   24|\n|COMPUTER SOFTWARES|   25|\n|           DINNING|   11|\n|          SHOPPING|   30|\n|       RESTAURANTS|   37|\n|       ELECTRONICS|   13|\n|          BUILDING|    6|\n|        RESTAURANT|   20|\n|   HOME APPLIANCES|   13|\n+------------------+-----+\n\n"
     ]
    }
   ],
   "source": [
    "# Number of loans in each category\n",
    "loan_df.groupBy(\"Loan Category\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dee0efd6-8ca4-493c-9b55-41fea30862e5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[14]: 0"
     ]
    }
   ],
   "source": [
    "# Number of people who have taken more than 1 lakh loan\n",
    "loan_df.filter(loan_df[\"Loan Amount\"] > 100000).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "82aa3d63-58a5-4873-a85e-b1246f451d50",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[15]: 192"
     ]
    }
   ],
   "source": [
    "# Number of people with income greater than 60,000 rupees\n",
    "loan_df.filter(loan_df[\"income\"] > 60000).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6488b914-89a0-4d7b-84e5-969eb9f26909",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[19]: 6"
     ]
    }
   ],
   "source": [
    "# Number of people with expenditure over 50,000 a month\n",
    "loan_df.filter(loan_df[\"Expenditure\"] > 50000).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "462c030b-8d32-4580-ab14-35f20c41785b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[20]: 0"
     ]
    }
   ],
   "source": [
    "# Number of members eligible for a credit card\n",
    "loan_df.filter((loan_df[\"Income\"] > 60000) & (loan_df[\"Loan Amount\"] < 100000)).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "268dc784-92f4-4d7d-a146-198edd764004",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[21]: 2477"
     ]
    }
   ],
   "source": [
    "# Credit card users in Spain\n",
    "credit_df.filter(credit_df[\"Geography\"] == \"Spain\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "88b9af9c-28f4-4d30-b28f-82352b3fe465",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[22]: 2655"
     ]
    }
   ],
   "source": [
    "# Number of members who are eligible and active in the bank\n",
    "credit_df.filter((credit_df[\"creditscore\"] > 650) & (credit_df[\"isactivemember\"] == 1)).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9541dddc-b5e6-44bd-97c0-c4fba1646526",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Withdrawal Amount: ₹459,447,546.4\n"
     ]
    }
   ],
   "source": [
    "# Maximum withdrawal amount in transactions\n",
    "from pyspark.sql.functions import col\n",
    "txn_df_filtered = txn_df.filter(col(\" WITHDRAWAL AMT \").isNotNull())\n",
    "max_withdrawal_row = txn_df_filtered.agg({\" WITHDRAWAL AMT \": \"max\"}).collect()[0]\n",
    "max_withdrawal_amt = max_withdrawal_row[0]\n",
    "formatted_max_withdrawal_amt = f\"₹{max_withdrawal_amt:,.1f}\"\n",
    "print(\"Maximum Withdrawal Amount:\", formatted_max_withdrawal_amt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6441390d-eb81-4048-8c89-f211345b8fd8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum Withdrawal Amount: ₹0.01\n"
     ]
    }
   ],
   "source": [
    "# Minimum withdrawal amount of an account\n",
    "from pyspark.sql.functions import col\n",
    "txn_df_filtered = txn_df.filter(col(\" WITHDRAWAL AMT \").isNotNull())\n",
    "min_withdrawal_row= txn_df_filtered.agg({\" WITHDRAWAL AMT \": \"min\"}).collect()[0]\n",
    "min_withdrawal_amt = min_withdrawal_row[0]\n",
    "formatted_min_withdrawal_amt = f\"₹{min_withdrawal_amt:,.2f}\"\n",
    "print(\"Minimum Withdrawal Amount:\", formatted_min_withdrawal_amt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6fd64722-f026-435a-9bf0-befa8a754a26",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Deposit Amount: ₹544,800,000.0\n"
     ]
    }
   ],
   "source": [
    "# Maximum deposit amount of an account\n",
    "from pyspark.sql.functions import col\n",
    "txn_df_filtered = txn_df.filter(col(\" DEPOSIT AMT \").isNotNull())\n",
    "max_deposit_row = txn_df_filtered.agg({\" DEPOSIT AMT \": \"max\"}).collect()[0]\n",
    "max_deposit_amt = max_deposit_row[0]\n",
    "formatted_max_deposit_amt = f\"₹{max_deposit_amt:,.1f}\"\n",
    "print(\"Maximum Deposit Amount:\", formatted_max_deposit_amt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d1f3df17-6581-4515-be79-ae3cc64a3b72",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum Deposit Amount: ₹0.01\n"
     ]
    }
   ],
   "source": [
    "# Minimum deposit amount of an account\n",
    "from pyspark.sql.functions import col\n",
    "txn_df_filtered = txn_df.filter(col(\" DEPOSIT AMT \").isNotNull())\n",
    "min_deposit_row = txn_df_filtered.agg({\" DEPOSIT AMT \": \"min\"}).collect()[0]\n",
    "min_deposit_amt = min_deposit_row[0]\n",
    "formatted_min_deposit_amt = f\"₹{min_deposit_amt:,.2f}\"\n",
    "print(\"Minimum Deposit Amount:\", formatted_min_deposit_amt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7778619e-23f3-488d-8a25-4594ba868a80",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------------+-----------------+\n|Account no   |Total Balance       |Formatted Balance|\n+-------------+--------------------+-----------------+\n|409000611074'|1.615533622E9       |1,615,533,622.00 |\n|409000425051'|8.649102501000117E8 |864,910,250.10   |\n|409000493201'|1.0420831829499985E9|1,042,083,182.95 |\n+-------------+--------------------+-----------------+\n\n"
     ]
    }
   ],
   "source": [
    "# Sum of balance in every bank account\n",
    "from pyspark.sql.functions import col, format_number\n",
    "txn_df = txn_df.withColumn(\"BALANCE AMT\", col(\"BALANCE AMT\").cast(\"double\"))\n",
    "txn_df_filtered = txn_df.filter((col(\"BALANCE AMT\") > 0) & (col(\"BALANCE AMT\").isNotNull()))\n",
    "result_df = txn_df_filtered.groupBy(\"Account no\").agg({\"BALANCE AMT\": \"sum\"})\n",
    "result_df = result_df.withColumnRenamed(\"sum(BALANCE AMT)\", \"Total Balance\")\n",
    "result_df = result_df.withColumn(\"Formatted Balance\", format_number(\"Total Balance\", 2))\n",
    "result_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a278e4a1-89e0-4d4e-9608-09f7dd189b78",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n|VALUE DATE|count|\n+----------+-----+\n| 23-Dec-16|  143|\n|  7-Feb-19|   98|\n| 21-Jul-15|   80|\n|  9-Sep-15|   91|\n| 17-Jan-15|   16|\n| 18-Nov-17|   53|\n| 21-Feb-18|   77|\n| 20-Mar-18|   71|\n| 19-Apr-18|   71|\n| 21-Jun-16|   97|\n| 17-Oct-17|  101|\n|  3-Jan-18|   70|\n|  8-Jun-18|  223|\n| 15-Dec-18|   62|\n|  8-Aug-16|   97|\n| 17-Dec-16|   74|\n|  3-Sep-15|   83|\n| 21-Jan-16|   76|\n|  4-May-18|   92|\n|  7-Sep-17|   94|\n+----------+-----+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "# Number of transactions on each date\n",
    "from pyspark.sql.functions import col\n",
    "txn_df_filtered = txn_df.filter(col(\"VALUE DATE\").isNotNull())\n",
    "txn_df_filtered.groupBy(\"VALUE DATE\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bef87016-8518-4b4a-ac81-b112cc5255e2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n|   Account No|\n+-------------+\n|409000611074'|\n|409000611074'|\n|409000611074'|\n|409000611074'|\n|409000611074'|\n|409000611074'|\n|409000611074'|\n|409000611074'|\n|409000611074'|\n|409000611074'|\n|409000611074'|\n|409000611074'|\n|409000611074'|\n|409000611074'|\n|409000611074'|\n|409000611074'|\n|409000611074'|\n|409000611074'|\n|409000611074'|\n|409000611074'|\n+-------------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "# List of customers with withdrawal amount more than 1 lakh\n",
    "from pyspark.sql.functions import col\n",
    "txn_df_filtered = txn_df.filter(col(\" WITHDRAWAL AMT \").isNotNull())\n",
    "txn_df.filter(txn_df[\" WITHDRAWAL AMT \"] > 100000).select(\"Account No\").show()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Pyspark casestudy",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
